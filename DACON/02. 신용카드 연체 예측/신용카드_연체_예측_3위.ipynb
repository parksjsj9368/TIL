{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\dask\\config.py:131: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/user/Desktop/open/train.csv')\n",
    "test = pd.read_csv('C:/Users/user/Desktop/open/test.csv')\n",
    "submission = pd.read_csv('C:/Users/user/Desktop/open/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26457, 20)\n",
      "(10000, 19)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE_SET_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26457 entries, 0 to 26456\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   gender             26457 non-null  int32   \n",
      " 1   car                26457 non-null  int32   \n",
      " 2   reality            26457 non-null  int32   \n",
      " 3   child_num          26457 non-null  int64   \n",
      " 4   income_total       26457 non-null  int32   \n",
      " 5   income_type        26457 non-null  float64 \n",
      " 6   edu_type           26457 non-null  int32   \n",
      " 7   family_type        26457 non-null  int32   \n",
      " 8   house_type         26457 non-null  int32   \n",
      " 9   DAYS_BIRTH         26457 non-null  int64   \n",
      " 10  DAYS_EMPLOYED      26457 non-null  int64   \n",
      " 11  FLAG_MOBIL         26457 non-null  int64   \n",
      " 12  phone              26457 non-null  int64   \n",
      " 13  email              26457 non-null  int64   \n",
      " 14  occyp_type         26457 non-null  int32   \n",
      " 15  begin_month        26457 non-null  int32   \n",
      " 16  credit             26457 non-null  category\n",
      " 17  birth_plus         26457 non-null  int32   \n",
      " 18  income_weight      26457 non-null  float64 \n",
      " 19  income_age         26457 non-null  int64   \n",
      " 20  income_emp         26457 non-null  int64   \n",
      " 21  DAYS_BIRTH_weight  26457 non-null  float64 \n",
      "dtypes: category(1), float64(3), int32(10), int64(8)\n",
      "memory usage: 3.3 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [train, test]:\n",
    "    \n",
    "    ## 변수 변환\n",
    "    data['birth_plus'] = data.DAYS_BIRTH*(-1)/365\n",
    "    \n",
    "    ## 라벨 인코딩\n",
    "    data['gender']=LabelEncoder().fit_transform(data.gender)\n",
    "    data['car']=LabelEncoder().fit_transform(data.car)\n",
    "    data['reality']=LabelEncoder().fit_transform(data.reality)\n",
    "    data['income_type']=LabelEncoder().fit_transform(data.income_type)\n",
    "    data['edu_type']=LabelEncoder().fit_transform(data.edu_type)\n",
    "    data['family_type']=LabelEncoder().fit_transform(data.family_type)\n",
    "    data['house_type']=LabelEncoder().fit_transform(data.house_type)\n",
    "    data.fillna('NAN',inplace=True)\n",
    "    data['occyp_type']=LabelEncoder().fit_transform(data.occyp_type)\n",
    "    \n",
    "    ## type 변환\n",
    "    data.income_total=data.income_total.astype(int)\n",
    "    data.family_size=data.family_size.astype(int)\n",
    "    data.begin_month=data.begin_month.astype(int)\n",
    "    data.birth_plus=data.birth_plus.astype(int)\n",
    "\n",
    "    ## 변수 제거\n",
    "    data.drop(['index','family_size','work_phone'],axis=1,inplace=True)\n",
    "    \n",
    "    ## 파생 변수 생성\n",
    "    data['income_weight']=data.income_total**2\n",
    "    data['income_age']=data.income_total*train.DAYS_BIRTH\n",
    "    data['income_emp']=data.income_total*train.DAYS_EMPLOYED\n",
    "    ## 파생 변수 생성\n",
    "    data.DAYS_BIRTH=data.DAYS_BIRTH**6\n",
    "    data.income_type=1/(data.income_type)\n",
    "    data.income_weight=1/(data.income_weight)**3\n",
    "    data['DAYS_BIRTH_weight']=1/(data.DAYS_BIRTH)**2\n",
    "\n",
    "## catboost는 categorical로 두면 안 됨\n",
    "cat_credit=train.credit.astype('int').copy()\n",
    "train.credit=train.credit.astype('category')\n",
    "\n",
    "## feature_set 1 저장\n",
    "ftr1 = train.drop('credit', axis=1).values\n",
    "target1 = train['credit'].values\n",
    "tst_ar1 = test.values # 행단위 list\n",
    "n_class = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             10000 non-null  int32  \n",
      " 1   car                10000 non-null  int32  \n",
      " 2   reality            10000 non-null  int32  \n",
      " 3   child_num          10000 non-null  int64  \n",
      " 4   income_total       10000 non-null  int32  \n",
      " 5   income_type        10000 non-null  float64\n",
      " 6   edu_type           10000 non-null  int32  \n",
      " 7   family_type        10000 non-null  int32  \n",
      " 8   house_type         10000 non-null  int32  \n",
      " 9   DAYS_BIRTH         10000 non-null  int64  \n",
      " 10  DAYS_EMPLOYED      10000 non-null  int64  \n",
      " 11  FLAG_MOBIL         10000 non-null  int64  \n",
      " 12  phone              10000 non-null  int64  \n",
      " 13  email              10000 non-null  int64  \n",
      " 14  occyp_type         10000 non-null  int32  \n",
      " 15  begin_month        10000 non-null  int32  \n",
      " 16  birth_plus         10000 non-null  int32  \n",
      " 17  income_weight      10000 non-null  float64\n",
      " 18  income_age         10000 non-null  float64\n",
      " 19  income_emp         10000 non-null  float64\n",
      " 20  DAYS_BIRTH_weight  10000 non-null  float64\n",
      "dtypes: float64(5), int32(10), int64(6)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE_SET2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 불러오기\n",
    "trn = pd.read_csv('data/train.csv')\n",
    "tst = pd.read_csv('data/test.csv')\n",
    "\n",
    "## 365 변환\n",
    "def days_to_plus(x):\n",
    "    return (x*-1)/365\n",
    "\n",
    "## 업무 시작일 변환\n",
    "def plus(x):\n",
    "    if x<0:\n",
    "        return x*(-1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "## 변수 변환 (업무 시작일과 나이)\n",
    "for i in [trn, tst]:\n",
    "    i['birth_plus'] = i.DAYS_BIRTH.map(days_to_plus)\n",
    "    i['employed_plus'] = i.DAYS_EMPLOYED.map(days_to_plus)\n",
    "\n",
    "\n",
    "## 라벨 인코딩\n",
    "index_col = 'index'\n",
    "target_col = 'credit'\n",
    "\n",
    "cat_cols = [x for x in trn.columns if trn[x].dtype == 'object']\n",
    "float_cols = [x for x in trn.columns.drop('credit') if trn[x].dtype == 'float64']\n",
    "num_cols = [x for x in trn.columns if x not in cat_cols + [target_col]]\n",
    "feature_cols = num_cols + cat_cols\n",
    "\n",
    "lbe = LabelEncoder()\n",
    "for i in cat_cols:\n",
    "    trn[i] = lbe.fit_transform(trn[i].astype(str))\n",
    "    tst[i] = lbe.transform(tst[i].astype(str))\n",
    "    \n",
    "for i in float_cols:\n",
    "    trn[i] = trn[i].astype('int')\n",
    "    tst[i] = tst[i].astype('int')\n",
    "    \n",
    "\n",
    "## 인덱스 설정 및 변수 제거\n",
    "for i in [trn, tst]:\n",
    "    i.set_index('index', inplace = True)\n",
    "    i.drop(['family_size', 'employed_plus'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "## 파생변수 생성\n",
    "for i in [trn,tst]:\n",
    "    # 연봉 제곱 변수 제거\n",
    "    i['income_total_2'] = i.income_total**2\n",
    "\n",
    "    # DAYS_BIRTH 제곱 변수 추가\n",
    "    i['DAYS_BIRTH**2'] = i.DAYS_BIRTH**2\n",
    "\n",
    "    # income * days_birth\n",
    "    i['income_age'] = i.income_total*i.DAYS_BIRTH\n",
    "\n",
    "    # income * DAYS_EMPLOYED\n",
    "    i['income_emp'] = i.income_total*i.DAYS_EMPLOYED\n",
    "\n",
    "\n",
    "## 데이터 재표현 (비선형 변환)\n",
    "for i in [trn, tst]:\n",
    "    i['DAYS_BIRTH**2'] = np.log1p(i['DAYS_BIRTH**2'])\n",
    "    i['income_total_2'] = i.income_total_2**2\n",
    "    i['income_emp'] = i.income_emp**2\n",
    "    i['income_age'] = i.income_age**3\n",
    "\n",
    "\n",
    "## 변수 타입 전환\n",
    "for i in [trn, tst]:\n",
    "    i['income_total'] = i.income_total.astype(int)\n",
    "    i['DAYS_BIRTH**2'] = i['DAYS_BIRTH**2'].astype(int)\n",
    "trn.credit = trn.credit.astype('category')\n",
    "\n",
    "\n",
    "## feature_set 2 저장\n",
    "ftr2 = trn.drop('credit', axis=1).values\n",
    "target2 = trn['credit'].values\n",
    "tst_ar2 = tst.values\n",
    "n_class = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGB_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 17\n",
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=40)\n",
    "\n",
    "print(ftr1.shape)\n",
    "\n",
    "lgb_p_val1 = np.zeros((ftr1.shape[0], n_class))\n",
    "lgb_p_tst1 = np.zeros((tst_ar1.shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(ftr1, target1), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    lgb_clf = LGBMClassifier(max_depth=24,\n",
    "                       num_leaves=110,\n",
    "                       colsample_bytree=0.3,\n",
    "                       n_estimators=230, \n",
    "                       min_child_samples=2,\n",
    "                       subsample=0.9,\n",
    "                       subsample_freq=2,\n",
    "                       learning_rate=0.09,\n",
    "                       random_state=2021,\n",
    "                       verbose = 50)\n",
    "\n",
    "    lgb_clf.fit(ftr1[i_trn], target1[i_trn],\n",
    "            eval_set=[(ftr1[i_val], target1[i_val])])\n",
    "\n",
    "    lgb_p_val1[i_val, :] = lgb_clf.predict_proba(ftr1[i_val])\n",
    "    lgb_p_tst1 += lgb_clf.predict_proba(tst_ar1) / n_fold\n",
    "    \n",
    "print(f'{log_loss(target1, lgb_p_val1)}')\n",
    "print(f'{confusion_matrix(target1, np.argmax(lgb_p_val1, axis=1))}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "tst_dir = Path('C:/Users/koko4/Desktop/credit/')\n",
    "val_dir = Path('C:/Users/koko4/Desktop/credit/')\n",
    "\n",
    "algo_name = 'lgb'\n",
    "feature_name = '2021_j'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "\n",
    "np.savetxt(p_val_file, lgb_p_val, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, lgb_p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGB_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 17\n",
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=40)\n",
    "\n",
    "print(ftr1.shape)\n",
    "\n",
    "lgb_p_val2 = np.zeros((ftr1.shape[0], n_class))\n",
    "lgb_p_tst2 = np.zeros((tst_ar1.shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(ftr1, target1), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    lgb_clf = lgb.LGBMClassifier(max_depth=24,\n",
    "                       num_leaves=110,\n",
    "                       colsample_bytree=0.3,\n",
    "                       n_estimators=175, \n",
    "                       min_child_samples=2,\n",
    "                       subsample=0.9,\n",
    "                       subsample_freq=2,\n",
    "                       learning_rate=0.09,\n",
    "                       random_state=2021,\n",
    "                       verbose = 0)\n",
    "\n",
    "    lgb_clf.fit(ftr1[i_trn], target1[i_trn],\n",
    "            eval_set=[(ftr1[i_val], target1[i_val])])\n",
    "\n",
    "    lgb_p_val2[i_val, :] = lgb_clf.predict_proba(ftr1[i_val])\n",
    "    lgb_p_tst2 += lgb_clf.predict_proba(tst_ar1) / n_fold\n",
    "    \n",
    "print(f'{log_loss(target1, lgb_p_val2)}')\n",
    "print(confusion_matrix(target1, np.argmax(lgb_p_val2, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "tst_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/tst')\n",
    "val_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/val')\n",
    "\n",
    "algo_name = 'lgb'\n",
    "feature_name = '2021'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "\n",
    "np.savetxt(p_val_file, lgb_p_val, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, lgb_p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드 서치\n",
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv=10, scoring_fit='accuracy',\n",
    "                       do_probabilities = False):\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid, \n",
    "        cv=cv, \n",
    "        n_jobs=8, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=2\n",
    "    )\n",
    "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
    "    \n",
    "    if do_probabilities:\n",
    "        pred = fitted_model.predict_proba(X_test_data)\n",
    "    else:\n",
    "        pred = fitted_model.predict(X_test_data)\n",
    "    \n",
    "    return fitted_model, pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train,X_val,y_train,y_val=train_test_split(ftr1,target1,test_size=0.25,random_state=40)\n",
    "\n",
    "\n",
    "# 모델 객체 생성\n",
    "model = HistGradientBoostingClassifier()\n",
    "\n",
    "\n",
    "paramgrid = {'max_iter' : [1000],\n",
    "            'learning_rate' : [0.08, 0.09, 0.1, 0.11],\n",
    "             'max_depth' : [15,17,18,20,22,24,26, 28, 30],\n",
    "             'max_leaf_nodes' : [26,28,30, 31, 32, 33, 34],\n",
    "             'random_state' : [2021]\n",
    "            }\n",
    "\n",
    "\n",
    "model, pred = algorithm_pipeline(X_train, X_val, y_train, y_val, model, \n",
    "                                 paramgrid, cv=10, scoring_fit='accuracy')\n",
    "\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "print(ftr1.shape)\n",
    "print(tst_ar1.shape)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=40)\n",
    " \n",
    "hgb_p_val = np.zeros((ftr1.shape[0], n_class))\n",
    "hgb_p_tst = np.zeros((tst_ar1.shape[0], n_class))\n",
    " \n",
    "for i, (i_trn, i_val) in enumerate(cv.split(ftr1, target1), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    hgb_clf = HistGradientBoostingClassifier(max_iter=1000,\n",
    "                                             learning_rate = 0.08,\n",
    "                                                verbose=True,\n",
    "                                             max_leaf_nodes = 33,\n",
    "                                             max_depth = 18,\n",
    "                                                random_state=2021\n",
    "                                                )\n",
    "    hgb_clf.fit(ftr1[i_trn], target1[i_trn])\n",
    "    hgb_p_val[i_val, :] = hgb_clf.predict_proba(ftr1[i_val])\n",
    "    hgb_p_tst += hgb_clf.predict_proba(tst_ar1) / n_fold\n",
    "    \n",
    "print(f'{log_loss(target1, hgb_p_val)}')\n",
    "print(confusion_matrix(target1, np.argmax(hgb_p_val, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "tst_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/tst')\n",
    "val_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/val')\n",
    "\n",
    "algo_name = 'hgbm'\n",
    "feature_name = '2021'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "\n",
    "np.savetxt(p_val_file, hgb_p_val, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, hgb_p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 17\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=40)\n",
    "\n",
    "print(ftr1.shape)\n",
    "\n",
    "xgb_p_val = np.zeros((ftr1.shape[0], n_class))\n",
    "xgb_p_tst = np.zeros((tst_ar1.shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(ftr1, target1), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    xgb_clf = xgb.XGBClassifier(max_depth=10,\n",
    "                                colsample_bytree=0.5,\n",
    "                                colsample_bylevel=0.8,\n",
    "                                colsample_bynode=0.5,\n",
    "                                min_child_weight=0.5,\n",
    "                                gamma=0,\n",
    "                                max_delta_step=0,\n",
    "                                subsample=0.9,\n",
    "                                reg_alpha=0.09,\n",
    "                                reg_lambda=0.6,\n",
    "                                n_estimators=50,\n",
    "                               random_state = 2021)\n",
    "\n",
    "    xgb_clf.fit(ftr1[i_trn], target1[i_trn],\n",
    "            eval_set=[(ftr1[i_val], target1[i_val])])\n",
    "    \n",
    "    xgb_p_val[i_val, :] = xgb_clf.predict_proba(ftr1[i_val])\n",
    "    xgb_p_tst += xgb_clf.predict_proba(tst_ar1) / n_fold\n",
    "\n",
    "\n",
    "print(f'{log_loss(target1, xgb_p_val)}')\n",
    "print(confusion_matrix(target1, np.argmax(xgb_p_val, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "tst_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/tst')\n",
    "val_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/val')\n",
    "\n",
    "algo_name = 'xgb'\n",
    "feature_name = '2021'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "\n",
    "np.savetxt(p_val_file, xgb_p_val, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, xgb_p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "target1 = cat_credit.values\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=2020)\n",
    " \n",
    "print(ftr1.shape)\n",
    " \n",
    "cb_p_val = np.zeros((ftr1.shape[0], n_class))\n",
    "cb_p_tst = np.zeros((tst_ar1.shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(ftr1, target1), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    cb_clf = CatBoostClassifier(depth=8,\n",
    "                                iterations=2000,\n",
    "                                rsm=0.7,\n",
    "                                ignored_features=5,\n",
    "                                learning_rate=0.04,\n",
    "                                l2_leaf_reg=1,\n",
    "                               random_state = 2021)\n",
    "    \n",
    "    cb_clf.fit(ftr1[i_trn], target1[i_trn],\n",
    "    eval_set=[(ftr1[i_val], target1[i_val])])\n",
    "    \n",
    "    cb_p_val[i_val, :] = cb_clf.predict_proba(ftr1[i_val])\n",
    "    cb_p_tst += cb_clf.predict_proba(tst_ar1) / n_fold\n",
    "\n",
    "    \n",
    "print(f'{log_loss(target1, cb_p_val)}')\n",
    "print(confusion_matrix(target1, np.argmax(cb_p_val, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "tst_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/tst')\n",
    "val_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/val')\n",
    "\n",
    "algo_name = 'cat'\n",
    "feature_name = '2021'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "\n",
    "np.savetxt(p_val_file, cb_p_val, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, cb_p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "\n",
    "print(ftr2.shape)\n",
    "print(tst_ar2.shape)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=40)\n",
    "\n",
    "rf_p_val = np.zeros((ftr2.shape[0], n_class))\n",
    "rf_p_tst = np.zeros((tst_ar2.shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(ftr2, target2), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    rf_clf = RandomForestClassifier(n_estimators = 7000, \n",
    "                                random_state=2021,\n",
    "                                max_features = 3,\n",
    "                                max_depth = 28,\n",
    "                                min_samples_split = 8,\n",
    "                                n_jobs=4)\n",
    "    \n",
    "    rf_clf.fit(ftr2[i_trn], target2[i_trn])\n",
    "    rf_p_val[i_val, :] = rf_clf.predict_proba(ftr2[i_val])\n",
    "    rf_p_tst += rf_clf.predict_proba(tst_ar2) / n_fold\n",
    "    \n",
    "print(f'{log_loss(target2, rf_p_val)}')\n",
    "print(confusion_matrix(target2, np.argmax(rf_p_val, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "tst_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/tst')\n",
    "val_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/val')\n",
    "\n",
    "algo_name = 'rf'\n",
    "feature_name = '2021'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "\n",
    "np.savetxt(p_val_file, rf_p_val, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, rf_p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "\n",
    "print(ftr2.shape)\n",
    "print(tst_ar2.shape)\n",
    "\n",
    "cv = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = 42)\n",
    "\n",
    "ext_p_val = np.zeros((ftr2.shape[0], n_class))\n",
    "ext_p_tst = np.zeros((tst_ar2.shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(ftr2, target2), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    ext_clf = ExtraTreesClassifier(\n",
    "                                   max_depth = 30, \n",
    "                                   max_features = 4, \n",
    "                                   min_samples_split = 9, \n",
    "                                   n_estimators = 7000, \n",
    "                                   random_state = 2021,\n",
    "                                  n_jobs = 4)\n",
    "\n",
    "    ext_clf.fit(ftr2[i_trn], target2[i_trn])\n",
    "    ext_p_val[i_val, :] = ext_clf.predict_proba(ftr2[i_val])\n",
    "    ext_p_tst += ext_clf.predict_proba(tst_ar2) / n_fold\n",
    "\n",
    "print(f'{log_loss(target2, ext_p_val)}')\n",
    "print(confusion_matrix(target2, np.argmax(ext_p_val, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "tst_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/tst')\n",
    "val_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/val')\n",
    "\n",
    "algo_name = 'extra'\n",
    "feature_name = '0.711'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "\n",
    "np.savetxt(p_val_file, ext_p_val, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, ext_p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/tst')\n",
    "val_dir = Path('C:/Users/Roh Seung Chan/Desktop/공모전/신용카드 예측 공모전/data/val')\n",
    "\n",
    "model_names = ['rf_2021',\n",
    "               'xgb_2021',\n",
    "               'lgb_2021',\n",
    "                 'extra_2021',\n",
    "                'cat_2021',\n",
    "               'lgb_2021_1',\n",
    "                'hgbm_2021'\n",
    "              ]\n",
    "\n",
    "\n",
    "stk_trn = []\n",
    "stk_tst = []\n",
    "feature_names = []\n",
    "for model in model_names:\n",
    "    stk_trn.append(np.loadtxt(val_dir / f'{model}.val.csv', delimiter=','))\n",
    "    stk_tst.append(np.loadtxt(tst_dir / f'{model}.tst.csv', delimiter=','))\n",
    "    feature_names += [f'{model}_credit0', f'{model}_credit1', f'{model}_credit2']\n",
    "    \n",
    "stk_trn = np.hstack(stk_trn)\n",
    "stk_tst = np.hstack(stk_tst)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stk_trn.shape\n",
    "stk_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 불러오기\n",
    "trn = pd.read_csv('data/train.csv')\n",
    "tst = pd.read_csv('data/test.csv')\n",
    "\n",
    "n_fold = 13\n",
    "seed = 2021\n",
    "n_class = 3\n",
    "\n",
    "target=trn['credit'].values\n",
    "y=target.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=2021)\n",
    "\n",
    "p_trn =np.zeros((stk_trn.shape[0], 3))\n",
    "p_val = np.zeros((stk_trn.shape[0], 3))\n",
    "p_tst = np.zeros((stk_tst.shape[0], 3))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(stk_trn, y), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    clf = lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                             max_depth=2,\n",
    "                             num_leaves=10,\n",
    "                             colsample_bytree=0.9,\n",
    "                             n_estimators=110, \n",
    "                             min_child_samples=24,\n",
    "                             subsample=0.5,\n",
    "                             subsample_freq=1,\n",
    "                             learning_rate=0.1,\n",
    "                             random_state=1557,\n",
    "                             verbose = 50)\n",
    "    \n",
    "    clf.fit(stk_trn[i_trn], y[i_trn],\n",
    "            eval_set=[(stk_trn[i_val], y[i_val])],\n",
    "            eval_metric='logloss',\n",
    "            verbose=True)\n",
    "\n",
    "    p_val[i_val, :] = clf.predict_proba(stk_trn[i_val])\n",
    "    p_tst += clf.predict_proba(stk_tst) / n_fold\n",
    "    \n",
    "print(clf)\n",
    "\n",
    "print(f'{log_loss(target, p_val)}')\n",
    "print(f'{confusion_matrix(target, np.argmax(p_val, axis=1))}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv', index_col = 0)\n",
    "sub[sub.columns] = p_tst\n",
    "sub.to_csv('stack_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
